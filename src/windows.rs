//! The `WaitOnAddress` / `WakeByAddress*` functions provide a convenient futex-like interface,
//! but they are only available since Windows 8. They are implemented in the `futex` module.
//!
//! On earlier Windows versions we fall back on the undocumented NT Keyed Events API. By using the
//! address of the atomic as the key to wait on, we can get something with looks a lot like a futex.
//!
//! There is an important difference:
//! Before the thread goes to sleep it does not check a comparison value. Instead the
//! `NtReleaseKeyedEvent` function blocks, waiting for a thread to wake if there is none. (Compared
//! to the Futex wake function which will immediately return.)
//!
//! With every release event one thread is waked. Thus we need to keep track of how many waiters
//! there are in order to wake them all, and to prevent the release function from hanging
//! indefinitely.
#![allow(non_snake_case)]

use core::cell::Cell;
use core::mem;
use core::ptr;
use core::sync::atomic::{spin_loop_hint, AtomicUsize, Ordering};
use core::time::Duration;

use winapi::shared::basetsd::SIZE_T;
use winapi::shared::minwindef::{BOOL, DWORD, ULONG};
use winapi::shared::ntdef::{FALSE, NTSTATUS};
use winapi::shared::ntstatus::{STATUS_ALERTED, STATUS_SUCCESS, STATUS_TIMEOUT, STATUS_USER_APC};
use winapi::um::libloaderapi::{GetModuleHandleA, GetProcAddress};
use winapi::um::winnt::{ACCESS_MASK, BOOLEAN, EVENT_ALL_ACCESS, HANDLE, LPCSTR, PHANDLE, PVOID};

use crate::futex::{self, WakeupReason};
use crate::{RESERVED_BITS, RESERVED_MASK};

//
// Implementation of the Waiters trait
//
pub(crate) fn compare_and_wait(atomic: &AtomicUsize, compare: usize) {
    match BACKEND.get() {
        Backend::Wait(_) => futex::compare_and_wait(atomic, compare),
        Backend::Keyed(_) => {
            // Register the number of threads waiting. In theory we should be careful not to
            // overflow out of our counter bits. But it is impossible to have so many
            // threads waiting that it doesn't fit in 2^27 on 32-bit and 2^59 on 64-bit
            // (there would not be enough memory to hold their stacks).
            let mut current = atomic.load(Ordering::Relaxed);
            loop {
                if current & !RESERVED_MASK != compare {
                    return;
                }
                match atomic.compare_exchange_weak(
                    current,
                    current + 1,
                    Ordering::Relaxed,
                    Ordering::Relaxed,
                ) {
                    Ok(_) => break,
                    Err(x) => current = x,
                }
            }
            // If a spurious wakeup happens right after a thread stores a new value in `atomic`
            // but before it can send the signal, we have no way to detect it is spurious.
            // If we then would not be waiting when the real signal is send, the sending thread
            // may hang indefinitely.
            // There is no way to prevent this race, but as an extra protection we check the return
            // value and repark when the wakeup is definitely not due to the event.
            loop {
                if let WakeupReason::Unknown = wait_for_keyed_event(atomic, None) {
                    break;
                }
            }
            debug_assert!(atomic.load(Ordering::Relaxed) & !RESERVED_MASK != compare);
        }
        Backend::None => unreachable!(),
    }
}

pub(crate) fn store_and_wake(atomic: &AtomicUsize, new: usize) {
    match BACKEND.get() {
        Backend::Wait(_) => futex::store_and_wake(atomic, new),
        Backend::Keyed(_) => {
            let wake_count = atomic.swap(new, Ordering::Release) & RESERVED_MASK;
            release_keyed_events(atomic, wake_count);
        }
        Backend::None => unreachable!(),
    }
}

//
// Implementation of the Parker trait
//
const NOT_PARKED: usize = 0x0 << (RESERVED_BITS - 2);
const PARKED: usize = 0x1 << (RESERVED_BITS - 2);
const NOTIFIED: usize = 0x2 << (RESERVED_BITS - 2);

pub(crate) fn park(atomic: &AtomicUsize, timeout: Option<Duration>) {
    match BACKEND.get() {
        Backend::Wait(_) => futex::park(atomic, timeout),
        Backend::Keyed(_) => {
            let mut current = atomic.load(Ordering::SeqCst);
            loop {
                if current & STATE_MASK != NOT_PARKED {
                    panic!(
                        "Tried to call park on an atomic while \
                         another thread is already parked on it"
                    );
                }
                match atomic.compare_exchange_weak(
                    current,
                    current | PARKED,
                    Ordering::Relaxed,
                    Ordering::Relaxed,
                ) {
                    Ok(_) => break,
                    Err(x) => current = x,
                }
            }
            loop {
                let r = wait_for_keyed_event(atomic, timeout);
                if timeout.is_some() {
                    // We don't guarantee there are no spurious wakeups when there was a timeout
                    // supplied. Reset state to `NOT_PARKED`.
                    &atomic.fetch_and(!STATE_MASK, Ordering::Relaxed);
                    return;
                }
                if let WakeupReason::Unknown = r {
                    // The wakeup was not caused by an alert ot timeout, we know (almost) for sure
                    // if the status is set to NOTIFIED. But this remains inherently racy, see
                    // the `compare_and_wait` implementation.
                    if atomic.load(Ordering::Relaxed) & STATE_MASK == NOTIFIED {
                        break;
                    }
                }
            }
            // Reset state to `NOT_PARKED`.
            &atomic.fetch_and(!STATE_MASK, Ordering::Relaxed);
        }
        Backend::None => unreachable!(),
    }
}

pub(crate) fn unpark(atomic: &AtomicUsize) {
    match BACKEND.get() {
        Backend::Wait(_) => futex::unpark(atomic),
        Backend::Keyed(_) => {
            let current = atomic.load(Ordering::SeqCst);
            if atomic
                .compare_exchange(
                    current,
                    (current & !RESERVED_MASK) | NOTIFIED,
                    Ordering::Relaxed,
                    Ordering::Relaxed,
                )
                .is_ok()
            {
                // We were unable to switch the state to `NOTIFIED`; Some other thread must be in
                // the process of unparking it. Either way the parked thread is being waked, and
                // there is nothing for us to do.
                return;
            }
            release_keyed_events(atomic, 1);
        }
        Backend::None => unreachable!(),
    }
}

fn wait_for_keyed_event(atomic: &AtomicUsize, timeout: Option<Duration>) -> WakeupReason {
    if let Backend::Keyed(f) = BACKEND.get() {
        // We need to provide some unique key to wait on. The least significant bit must be
        // zero, it is appearently used as a flag bit. The address of `atomic` seems like a
        // good candidate.
        let key = atomic as *const AtomicUsize as PVOID;
        let nt_timeout = convert_timeout_100ns(timeout);
        let timeout_ptr = nt_timeout
            .map(|t_ref| t_ref as *mut _)
            .unwrap_or(ptr::null_mut());
        let r = (f.NtWaitForKeyedEvent)(f.handle, key, FALSE, timeout_ptr);
        // `NtWaitForKeyedEvent` is an undocumented API where we don't known the possible
        // return values, but they are most likely similar to `NtWaitForSingleObject`.
        match r {
            STATUS_SUCCESS => WakeupReason::Unknown,
            STATUS_TIMEOUT if nt_timeout.is_some() => WakeupReason::TimedOut,
            STATUS_ALERTED | STATUS_USER_APC => WakeupReason::Interrupt,
            r => {
                debug_assert!(
                    false,
                    "Unexpected return value of NtWaitForKeyedEvent: {}",
                    r
                );
                WakeupReason::Unknown
            }
        }
    } else {
        unreachable!();
    }
}

fn release_keyed_events(atomic: &AtomicUsize, wake_count: usize) {
    if let Backend::Keyed(f) = BACKEND.get() {
        // Recreate the key; the address of self.
        let key = atomic as *const AtomicUsize as PVOID;
        for _ in 0..wake_count {
            (f.NtReleaseKeyedEvent)(f.handle, key, 0, ptr::null_mut());
        }
    } else {
        unreachable!();
    }
}

// NT uses a timeout in units of 100ns, where positive values are absolute and negative values are
// relative.
fn convert_timeout_100ns(timeout: Option<Duration>) -> Option<LARGE_INTEGER> {
    match timeout {
        Some(duration) => {
            if duration.as_secs() > i64::max_value() as u64 {
                return None;
            }
            // Checked operations that return `None` on overflow.
            // Round nanosecond values up to 100 ns.
            (duration.as_secs() as i64)
                .checked_mul(-10_000_000)
                .and_then(|x| x.checked_sub((duration.subsec_nanos() as i64 + 99) / 100))
        }
        None => None,
    }
}

// Backend states
const READY: usize = 0;
const INITIALIZING: usize = 1;
const EMPTY: usize = 2;

pub(crate) struct BackendStatic {
    status: AtomicUsize,
    backend: Cell<Backend>,
}
pub(crate) static BACKEND: BackendStatic = BackendStatic::new();

impl BackendStatic {
    const fn new() -> Self {
        BackendStatic {
            status: AtomicUsize::new(EMPTY),
            backend: Cell::new(Backend::None),
        }
    }

    pub(crate) fn get(&self) -> Backend {
        if self.status.load(Ordering::Acquire) == READY {
            return self.backend.get();
        }
        self.init()
    }

    #[inline(never)]
    fn init(&self) -> Backend {
        let mut status = self
            .status
            .compare_and_swap(EMPTY, INITIALIZING, Ordering::Acquire);
        if status == EMPTY {
            let backend = if let Some(res) = ProbeWaitAddress() {
                Backend::Wait(res)
            } else if let Some(res) = ProbeKeyedEvent() {
                Backend::Keyed(res)
            } else {
                panic!(
                    "failed to load both NT Keyed Events (WinXP+) and \
                     WaitOnAddress/WakeByAddress (Win8+)"
                );
            };
            self.backend.set(backend);
            self.status.store(READY, Ordering::Release);
            return backend;
        }
        while status != READY {
            // The one place were we can't really do better than a spin loop is while another
            // thread is loading the functions that provide parking primitives ;-).
            spin_loop_hint();
            status = self.status.load(Ordering::Acquire);
        }
        self.backend.get()
    }
}

unsafe impl Sync for BackendStatic {}

#[derive(Clone, Copy)]
pub(crate) enum Backend {
    None,
    Wait(WaitAddress),
    Keyed(KeyedEvent),
}

// LARGE_INTEGER in WinAPI is a struct instead of integer, and not ergonomic to use.
#[allow(non_camel_case_types)]
type LARGE_INTEGER = i64;
#[allow(non_camel_case_types)]
type PLARGE_INTEGER = *mut LARGE_INTEGER;

#[derive(Clone, Copy)]
pub(crate) struct WaitAddress {
    pub(crate) WaitOnAddress: extern "system" fn(
        Address: PVOID,
        CompareAddress: PVOID,
        AddressSize: SIZE_T,
        dwMilliseconds: DWORD,
    ) -> BOOL,
    pub(crate) WakeByAddressAll: extern "system" fn(Address: PVOID),
}

#[derive(Clone, Copy)]
pub(crate) struct KeyedEvent {
    handle: HANDLE, // The global keyed event handle.
    NtReleaseKeyedEvent: extern "system" fn(
        EventHandle: HANDLE,
        Key: PVOID,
        Alertable: BOOLEAN,
        Timeout: PLARGE_INTEGER,
    ) -> NTSTATUS,
    NtWaitForKeyedEvent: extern "system" fn(
        EventHandle: HANDLE,
        Key: PVOID,
        Alertable: BOOLEAN,
        Timeout: PLARGE_INTEGER,
    ) -> NTSTATUS,
}

#[cfg(not(feature = "fallback"))]
fn ProbeWaitAddress() -> Option<WaitAddress> {
    unsafe {
        // MSDN claims that that WaitOnAddress and WakeByAddressAll are
        // located in kernel32.dll, but they aren't...
        let synch_dll = GetModuleHandleA(b"api-ms-win-core-synch-l1-2-0.dll\0".as_ptr() as LPCSTR);
        if synch_dll.is_null() {
            return None;
        }

        let WaitOnAddress = GetProcAddress(synch_dll, b"WaitOnAddress\0".as_ptr() as LPCSTR);
        if WaitOnAddress.is_null() {
            return None;
        }
        let WakeByAddressAll = GetProcAddress(synch_dll, b"WakeByAddressAll\0".as_ptr() as LPCSTR);
        if WakeByAddressAll.is_null() {
            return None;
        }

        Some(WaitAddress {
            WaitOnAddress: mem::transmute(WaitOnAddress),
            WakeByAddressAll: mem::transmute(WakeByAddressAll),
        })
    }
}

#[cfg(feature = "fallback")]
fn ProbeWaitAddress() -> Option<WaitAddress> {
    None
}

fn ProbeKeyedEvent() -> Option<KeyedEvent> {
    unsafe {
        let ntdll = GetModuleHandleA(b"ntdll.dll\0".as_ptr() as LPCSTR);
        if ntdll.is_null() {
            return None;
        }

        let NtCreateKeyedEvent = GetProcAddress(ntdll, b"NtCreateKeyedEvent\0".as_ptr() as LPCSTR);
        if NtCreateKeyedEvent.is_null() {
            return None;
        }
        let NtWaitForKeyedEvent =
            GetProcAddress(ntdll, b"NtWaitForKeyedEvent\0".as_ptr() as LPCSTR);
        if NtWaitForKeyedEvent.is_null() {
            return None;
        }
        let NtReleaseKeyedEvent =
            GetProcAddress(ntdll, b"NtReleaseKeyedEvent\0".as_ptr() as LPCSTR);
        if NtReleaseKeyedEvent.is_null() {
            return None;
        }

        let NtCreateKeyedEvent: extern "system" fn(
            KeyedEventHandle: PHANDLE,
            DesiredAccess: ACCESS_MASK,
            ObjectAttributes: PVOID,
            Flags: ULONG,
        ) -> NTSTATUS = mem::transmute(NtCreateKeyedEvent);
        let mut handle: HANDLE = ptr::null_mut();
        let status = NtCreateKeyedEvent(&mut handle, EVENT_ALL_ACCESS, ptr::null_mut(), 0);
        if status != STATUS_SUCCESS {
            return None;
        }

        Some(KeyedEvent {
            handle: handle,
            NtReleaseKeyedEvent: mem::transmute(NtReleaseKeyedEvent),
            NtWaitForKeyedEvent: mem::transmute(NtWaitForKeyedEvent),
        })
    }
}
