#![allow(non_snake_case)]

use core::cell::Cell;
use core::mem;
use core::ptr;
use core::sync::atomic::{AtomicUsize, Ordering, spin_loop_hint};

use winapi::shared::basetsd::SIZE_T;
use winapi::shared::minwindef::{BOOL, DWORD, TRUE, ULONG};
use winapi::shared::ntdef::NTSTATUS;
use winapi::shared::ntstatus::STATUS_SUCCESS;
use winapi::um::libloaderapi::{GetModuleHandleA, GetProcAddress};
use winapi::um::winbase::INFINITE;
use winapi::um::winnt::{
    ACCESS_MASK, BOOLEAN, GENERIC_READ, GENERIC_WRITE, HANDLE, LPCSTR, PHANDLE, PLARGE_INTEGER,
    PVOID,
};

use crate::{Waiters, RESERVED_MASK};

impl Waiters for AtomicUsize {
    unsafe fn wait<P>(&self, should_park: P)
    where
        P: Fn(usize) -> bool,
    {
        let backend = BACKEND.get();
        loop {
            let current = self.load(Ordering::Relaxed);
            if !should_park(current & !RESERVED_MASK) {
                break;
            }
            match backend {
                Backend::Wait(f) => {
                    let address = self as *const _ as PVOID;
                    let compare_address = &current as *const _ as PVOID;
                    let r = (f.WaitOnAddress)(
                        address,
                        compare_address,
                        mem::size_of::<AtomicUsize>(),
                        INFINITE,
                    );
                    debug_assert!(r == TRUE);
                }
                Backend::Keyed(f) => {
                    // Register the number of threads waiting. In theory we should be careful not to
                    // overflow out of our `RESERVED_BITS`. But it is impossible to have so many
                    // threads waiting that it doesn't fit in 2^27 on 32-bit and 2^59 in 64-bit
                    // (there would not be enough memory to hold their stacks).
                    self.fetch_add(1, Ordering::Relaxed);
                    // We need to provide some unique key to wait on, the address of `self` seems
                    // like a good candidate.
                    let key = self as *const AtomicUsize as PVOID;
                    (f.NtWaitForKeyedEvent)(f.handle, key, 0, ptr::null_mut());
                }
                Backend::None => unreachable!(),
            }
        }
    }

    unsafe fn store_and_wake(&self, new: usize) {
        match BACKEND.get() {
            Backend::Wait(f) => {
                self.store(new, Ordering::Release); // FIXME: maybe SeqCst?
                (f.WakeByAddressAll)(self as *const _ as PVOID);
            }
            Backend::Keyed(f) => {
                let current = self.swap(new, Ordering::Release); // FIXME: maybe SeqCst?
                let waiter_count = current & RESERVED_MASK;
                // Recreate the key; the address of self.
                let key = self as *const AtomicUsize as PVOID;
                // With every event we wake one thread. If we would try to wake a thread that is not
                // parked we will block indefinitely.
                for _ in 0..waiter_count {
                    (f.NtReleaseKeyedEvent)(f.handle, key, 0, ptr::null_mut());
                }
            }
            Backend::None => unreachable!(),
        }
    }
}

// Backend states
const READY: usize = 0;
const INITIALIZING: usize = 1;
const EMPTY: usize = 2;

struct BackendStatic {
    status: AtomicUsize,
    backend: Cell<Backend>,
}
static BACKEND: BackendStatic = BackendStatic::new();

impl BackendStatic {
    const fn new() -> Self {
        BackendStatic {
            status: AtomicUsize::new(EMPTY),
            backend: Cell::new(Backend::None),
        }
    }

    fn get(&self) -> Backend {
        if self.status.load(Ordering::Acquire) == READY {
            return self.backend.get();
        }
        self.init()
    }

    #[inline(never)]
    fn init(&self) -> Backend {
        let mut status = self.status.compare_and_swap(EMPTY, INITIALIZING, Ordering::Acquire);
        if status == EMPTY {
            let backend = if let Some(res) = ProbeWaitAddress() {
                Backend::Wait(res)
            } else if let Some(res) = ProbeKeyedEvent() {
                Backend::Keyed(res)
            } else {
                panic!(
                    "failed to load both NT Keyed Events (WinXP+) and \
                     WaitOnAddress/WakeByAddress (Win8+)"
                );
            };
            self.backend.set(backend);
            self.status.store(READY, Ordering::Release);
            return backend;
        }
        while status != READY {
            // The one place were we can't really do better than a spin loop is while another
            // thread is loading the functions that provide parking primitives ;-).
            spin_loop_hint();
            status = self.status.load(Ordering::Acquire);
        }
        self.backend.get()
    }
}

unsafe impl Sync for BackendStatic {}

#[derive(Clone, Copy)]
enum Backend {
    None,
    Wait(WaitAddress),
    Keyed(KeyedEvent),
}

#[derive(Clone, Copy)]
struct WaitAddress {
    WaitOnAddress: extern "system" fn(
        Address: PVOID,
        CompareAddress: PVOID,
        AddressSize: SIZE_T,
        dwMilliseconds: DWORD,
    ) -> BOOL,
    WakeByAddressAll: extern "system" fn(Address: PVOID),
}

#[derive(Clone, Copy)]
struct KeyedEvent {
    handle: HANDLE, // The global keyed event handle.
    NtReleaseKeyedEvent: extern "system" fn(
        EventHandle: HANDLE,
        Key: PVOID,
        Alertable: BOOLEAN,
        Timeout: PLARGE_INTEGER,
    ) -> NTSTATUS,
    NtWaitForKeyedEvent: extern "system" fn(
        EventHandle: HANDLE,
        Key: PVOID,
        Alertable: BOOLEAN,
        Timeout: PLARGE_INTEGER,
    ) -> NTSTATUS,
}

fn ProbeWaitAddress() -> Option<WaitAddress> {
    unsafe {
        // MSDN claims that that WaitOnAddress and WakeByAddressAll are
        // located in kernel32.dll, but they aren't...
        let synch_dll = GetModuleHandleA(b"api-ms-win-core-synch-l1-2-0.dll\0".as_ptr() as LPCSTR);
        if synch_dll.is_null() {
            return None;
        }

        let WaitOnAddress = GetProcAddress(synch_dll, b"WaitOnAddress\0".as_ptr() as LPCSTR);
        if WaitOnAddress.is_null() {
            return None;
        }
        let WakeByAddressAll = GetProcAddress(synch_dll, b"WakeByAddressAll\0".as_ptr() as LPCSTR);
        if WakeByAddressAll.is_null() {
            return None;
        }

        Some(WaitAddress {
            WaitOnAddress: mem::transmute(WaitOnAddress),
            WakeByAddressAll: mem::transmute(WakeByAddressAll),
        })
    }
}

fn ProbeKeyedEvent() -> Option<KeyedEvent> {
    unsafe {
        let ntdll = GetModuleHandleA(b"ntdll.dll\0".as_ptr() as LPCSTR);
        if ntdll.is_null() {
            return None;
        }

        let NtCreateKeyedEvent = GetProcAddress(ntdll, b"NtCreateKeyedEvent\0".as_ptr() as LPCSTR);
        if NtCreateKeyedEvent.is_null() {
            return None;
        }
        let NtWaitForKeyedEvent =
            GetProcAddress(ntdll, b"NtWaitForKeyedEvent\0".as_ptr() as LPCSTR);
        if NtWaitForKeyedEvent.is_null() {
            return None;
        }
        let NtReleaseKeyedEvent =
            GetProcAddress(ntdll, b"NtReleaseKeyedEvent\0".as_ptr() as LPCSTR);
        if NtReleaseKeyedEvent.is_null() {
            return None;
        }

        let NtCreateKeyedEvent: extern "system" fn(
            KeyedEventHandle: PHANDLE,
            DesiredAccess: ACCESS_MASK,
            ObjectAttributes: PVOID,
            Flags: ULONG,
        ) -> NTSTATUS = mem::transmute(NtCreateKeyedEvent);
        let mut handle: HANDLE = ptr::null_mut();
        let status = NtCreateKeyedEvent(
            &mut handle,
            GENERIC_READ | GENERIC_WRITE,
            ptr::null_mut(),
            0,
        );
        if status != STATUS_SUCCESS {
            return None;
        }

        Some(KeyedEvent {
            handle: handle,
            NtReleaseKeyedEvent: mem::transmute(NtReleaseKeyedEvent),
            NtWaitForKeyedEvent: mem::transmute(NtWaitForKeyedEvent),
        })
    }
}

// `NtWaitForKeyedEvent` allows a thread to go to sleep, waiting on the event signaled by
// `NtReleaseKeyedEvent`. The major different between this API and the Futex API is that there is no
// comparison value that is checked as the thread goes to sleep. Instead the `NtReleaseKeyedEvent`
// function blocks, waiting for a thread to wake if there is none. (Compared to the Futex wake
// function which will immediately return.)
//
// Thus to use this API we need to keep track of how many waiters there are to prevent the release
// function from hanging.
//
// http://joeduffyblog.com/2006/11/28/windows-keyed-events-critical-sections-and-new-vista-synchronization-features/
// http://locklessinc.com/articles/keyed_events/
